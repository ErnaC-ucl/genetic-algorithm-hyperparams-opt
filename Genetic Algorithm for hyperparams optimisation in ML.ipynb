{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Genetic Algorithm for hyperparams optimisation in ML.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMC16Ptu0xixZlVWcAh6gdz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6foj7FK0xmmo"},"source":["# Genetic Algorithm for hyperparameter tunning in Machine Learning Models \n","\n","**The ML model used for optimisation is the Kernel Ridge Regression:**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fRCHIbmwykNU"},"source":["## Step 1:  Generate data \n","We will use as an example a two dimensional function f(x1,x2)=sin(x1)+cos(x2)+random(-2,2). "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-F7u_076zhZ","executionInfo":{"status":"ok","timestamp":1631803206510,"user_tz":-60,"elapsed":356,"user":{"displayName":"Erna Ceka","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17436274315505671993"}},"outputId":"09ecda22-ff5c-499c-8f97-ee6c9c99f969"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.insert(0,\"/content/drive/My Drive/Colab Notebooks/\")"],"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"5dH5XDCZ8rXs","executionInfo":{"status":"ok","timestamp":1631807900959,"user_tz":-60,"elapsed":7,"user":{"displayName":"Erna Ceka","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17436274315505671993"}}},"source":["# Import packages \n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn import preprocessing\n","from sklearn.model_selection import KFold\n","from sklearn.kernel_ridge import KernelRidge\n","from sklearn.metrics import mean_squared_error\n","from scipy.optimize import differential_evolution"],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"qPJO_FY6TPXx","executionInfo":{"status":"ok","timestamp":1631807902792,"user_tz":-60,"elapsed":4,"user":{"displayName":"Erna Ceka","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17436274315505671993"}}},"source":["from genetic_algorithm import *"],"execution_count":129,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6zTiP_FC9J_l"},"source":["## Step 2: Model 1: Kernel Ridge Regression \n","\n","We will be using a radial basis function kernel for KRR which depends on the Gaussian Kernel variance (gamma). We also need to optimise the regularisation parameter (alpha). \n","\n","We will use a 10-fold cross validation where our data is split into a training set used to optimise the model and a test set used to measure the model accuracy. As an accuracy metric we will use RMSE.\n","\n","Prior to that we can perform a grid search to see how the RMSE changes with the values of our two hyperparameters: alpha and gamma. "]},{"cell_type":"code","metadata":{"id":"fh-EK-AHDd7k","executionInfo":{"status":"ok","timestamp":1631803393117,"user_tz":-60,"elapsed":487,"user":{"displayName":"Erna Ceka","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17436274315505671993"}}},"source":["#Define hyperparms grid for KKR\n","for alpha_value in np.arange(-5.0,2.2,0.2):\n","  alpha_value=pow(10,alpha_value)\n","  for gamma_value in np.arange(0.0, 20.1,0.1):\n","    hyperparams=(alpha_value,gamma_value)"],"execution_count":70,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bm33q6wpHEOt"},"source":["## Step 3: Hyperparameter tunnings\n","\n","Here we use the differential evolution algorithm provided by Scipy to optimise the hyperparameters by minimising the RMSE of our model.\n","\n","Scipy differential evolution function needs as inputs:\n","*   model that outputs the loss function which will be minimised\n","*   hyperparameter grid\n","*   dataset\n","*   boundaries of possible values of hyperparams\n","\n","There are other arguments that can be set such as: Strategy, Population Size, Mutation constant, Recombination constant, Tolerance.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16Jd3AfNFsnN","executionInfo":{"status":"ok","timestamp":1631809166583,"user_tz":-60,"elapsed":58965,"user":{"displayName":"Erna Ceka","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17436274315505671993"}},"outputId":"9c50624e-06e4-48a8-cd26-7f90de4b003b"},"source":["def main():\n","  x1,x2,f = generate_data(-10,10,1.0,2)\n","  # Prepare X and y for KRR\n","  X,y = prepare_data(x1,x2,f)\n","  # Set limits for Differential Evolution\n","  KRR_alpha_lim = (0.00001,100.0)\n","  KRR_gamma_lim = (0.00001,20.0)\n","  boundaries = [KRR_alpha_lim] + [KRR_gamma_lim]\n","  extra_variables = (X,y)\n","  # Set up Differential Evolution solver\n","  solver = differential_evolution(KRR_function,boundaries,args=extra_variables,strategy='best1bin',\n","                                  popsize=15,mutation=0.5,recombination=0.7,tol=0.01,seed=123)\n","  # Calculate best hyperparameters and resulting rmse\n","  best_hyperparams = solver.x\n","  best_rmse = solver.fun\n","  # Print final results\n","  print(\"Converged hyperparameters: alpha= %.6f, gamma= %.6f\" %(best_hyperparams[0],best_hyperparams[1]))    \n","  print(\"Minimum rmse: %.6f\" %(best_rmse))\n","main()"],"execution_count":144,"outputs":[{"output_type":"stream","name":"stdout","text":["Converged hyperparameters: alpha= 0.347262, gamma= 3.342419\n","Minimum rmse: 1.140462\n"]}]}]}